{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from misc_handler import extract_reviews_from_page,extract_all_reviews,scrape_amazon_reviews_df,return_specs_df,return_all_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "options=Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "url = 'https://www.phonearena.com/phones/Samsung-Galaxy-S23-FE_id12188'\n",
    "driver.get(url)\n",
    "#name=driver.find_elements(By.XPATH,'//*[@id=\"body\"]/div/div[1]/div/div[1]/h1')\n",
    "#name = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"body\"]/div/div[1]/div/div[1]/h1'))).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[0].columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[0][d22[0].columns[0]]=d22[0].columns[0]+'_'+d22[0][d22[0].columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= d22[0].T\n",
    "result.columns=result.iloc[0]\n",
    "data_row=result.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresult=pd.DataFrame([data_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=d22[0].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd=pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d1=pd.concat([d1,dd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(d22, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.json_normalize(response[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs=pd.json_normalize(response['snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(specs['ti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_html('https://phonedb.net/index.php?m=device&id=21724&c=samsung_sm-s918q_galaxy_s23_ultra_5g_uw_premium_edition_td-lte_jp_1tb__samsung_diamond_dm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_html('https://www.phonearena.com/phones/Samsung-Galaxy-S23-FE_id12188')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "res=d22[i].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd=pd.DataFrame([data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=dd.reset_index()\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "res=d22[i].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd2=pd.DataFrame([data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2=dd2.reset_index()\n",
    "dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([dd,dd2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)\n",
    "final = pd.DataFrame(columns=[0,1])\n",
    "for i in range(len(d22)):\n",
    "    d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "    d22[i].columns=[0,1]\n",
    "    #result = d22[i].T\n",
    "    #result.columns = result.iloc[0]\n",
    "    #data_row = result.iloc[1]\n",
    "    #fresult = pd.DataFrame([data_row])\n",
    "    #fresult=fresult.reset_index()\n",
    "    \n",
    "    if final is None:\n",
    "        final = fresult\n",
    "    else:\n",
    "        # Use ignore_index=True to concatenate without reindexing\n",
    "        final = pd.concat([final, d22[i]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)\n",
    "final = pd.DataFrame(columns=[0,1])\n",
    "for i in range(len(d22)):\n",
    "    d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "    d22[i].columns=[0,1]\n",
    "    #result = d22[i].T\n",
    "    #result.columns = result.iloc[0]\n",
    "    #data_row = result.iloc[1]\n",
    "    #fresult = pd.DataFrame([data_row])\n",
    "    #fresult=fresult.reset_index()\n",
    "    \n",
    "    if final is None:\n",
    "        final = fresult\n",
    "    else:\n",
    "        # Use ignore_index=True to concatenate without reindexing\n",
    "        final = pd.concat([final, d22[i]],axis=0)\n",
    "\n",
    "result=final.T\n",
    "result.columns=result.iloc[0]\n",
    "col=result.iloc[0]\n",
    "arena_df=result.iloc[1:,:]\n",
    "arena_df.iloc[:,10:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_row.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=4\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "res=d22[i].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd4=pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd4=dd4.reset_index()\n",
    "final = pd.concat([final, dd4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_handler import return_specs_df\n",
    "return_s23df=return_specs_df('https://www.gsmarena.com/google_pixel_8_pro-12545.php')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_s23df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "options=Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "#driver.get('https://www.gsmarena.com/samsung_galaxy_s23-reviews-12082.php')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=extract_all_reviews('https://www.gsmarena.com/alcatel_1b_(2022)-reviews-11706.php',driver=driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_elements = driver.find_elements(By.CLASS_NAME, 'user-thread')\n",
    "reviews = [review.text for review in review_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.gsmarena.com/samsung_galaxy_s23-reviews-12082p1.php')\n",
    "review_elements = driver.find_elements(By.CLASS_NAME, 'user-thread')\n",
    "\n",
    "# Loop through the review elements to extract user name, rating, and date\n",
    "reviews_data = []\n",
    "for review_element in review_elements:\n",
    "    user_name_element = review_element.find_element(By.XPATH, './/*[contains(@class, \"uname\") or contains(@class, \"uname2\")]')\n",
    "    user_location_element = review_element.find_element(By.CLASS_NAME, 'ulocation')\n",
    "    date_element = review_element.find_element(By.CLASS_NAME, 'upost')\n",
    "    text_element=review_element.find_element(By.CLASS_NAME, 'uopin')\n",
    "    \n",
    "    user_name = user_name_element.text\n",
    "    user_location = user_location_element.text\n",
    "    date = date_element.text\n",
    "    \n",
    "    review_text = text_element.text  # Extract the entire review text if needed\n",
    "    \n",
    "    reviews_data.append({\n",
    "        'User Name': user_name,\n",
    "        'User location': user_location,\n",
    "        'Date': date,\n",
    "        'Review Text': review_text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df=pd.DataFrame(reviews_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number=1\n",
    "driver.get(f'https://www.gsmarena.com/samsung_galaxy_s23-reviews-12082p{page_number}.php')\n",
    "review_elements = driver.find_elements(By.CLASS_NAME, 'user-thread')\n",
    "\n",
    "# Loop through the review elements to extract user name, rating, and date\n",
    "\n",
    "reviews_data = []\n",
    "for review_element in review_elements:\n",
    "    user_name_element = review_element.find_element(By.XPATH, './/*[contains(@class, \"uname\") or contains(@class, \"uname2\")]')\n",
    "    user_location_element = review_element.find_element(By.CLASS_NAME, 'ulocation')\n",
    "    date_element = review_element.find_element(By.CLASS_NAME, 'upost')\n",
    "    text_element=review_element.find_element(By.CLASS_NAME, 'uopin')\n",
    "    \n",
    "    user_name = user_name_element.text\n",
    "    user_location = user_location_element.text\n",
    "    date = date_element.text\n",
    "    \n",
    "    review_text = text_element.text  # Extract the entire review text if needed\n",
    "    \n",
    "    reviews_data.append({\n",
    "        'User Name': user_name,\n",
    "        'User location': user_location,\n",
    "        'Date': date,\n",
    "        'Review Text': review_text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scrape_amazon_reviews(search_query):\n",
    "    # Configure Selenium to use a web driver (e.g., ChromeDriver)\n",
    "    driver = webdriver.Chrome()\n",
    "    options=Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Navigate to Amazon's search results page\n",
    "    base_url = 'https://www.amazon.com/'\n",
    "    driver.get(base_url)\n",
    "    #search_box = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "    search_box = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.ID, 'twotabsearchtextbox')))\n",
    "    search_box.send_keys(search_query)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "    # Find and extract all product links on the search results page\n",
    "    product_links = driver.find_elements(By.CSS_SELECTOR, '.s-result-item a.a-link-normal.s-no-outline')\n",
    "    product_urls = [link.get_attribute('href') for link in product_links]\n",
    "\n",
    "    # Initialize a list to store reviews\n",
    "    all_reviews = []\n",
    "\n",
    "    # Loop through product links and extract reviews\n",
    "    for product_url in product_urls:\n",
    "        driver.get(product_url)\n",
    "        time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "        try:\n",
    "            # Extract the product name\n",
    "            product_name = driver.find_element(By.ID, 'productTitle').text\n",
    "\n",
    "            # Check if the product name contains the filter string (case-insensitive)\n",
    "            if search_query.lower() in product_name.lower():\n",
    "                # Click on the \"See all reviews\" link (if available)\n",
    "                try:\n",
    "                    see_all_reviews_link = driver.find_element(By.PARTIAL_LINK_TEXT, 'See more reviews')\n",
    "                    see_all_reviews_link.click()\n",
    "                    time.sleep(2)  # Adjust the sleep time as needed to allow the reviews page to load\n",
    "\n",
    "                    # Extract and store all reviews on the page\n",
    "                    review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "                    for review_element in review_elements:\n",
    "                        review_text = review_element.text\n",
    "                        all_reviews.append(review_text)\n",
    "                except Exception as e:\n",
    "                    print(f\"No 'See all reviews' link found for product: {product_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_amazon_reviews_df(search_query):\n",
    "    # Configure Selenium to use a web driver (e.g., ChromeDriver)\n",
    "    driver = webdriver.Chrome()\n",
    "    options=Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Navigate to Amazon's search results page\n",
    "    base_url = 'https://www.amazon.com/'\n",
    "    driver.get(base_url)\n",
    "    #search_box = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "    #earch_box = WebDriverWait(driver, 50).until(EC.element_to_be_clickable((By.ID, 'twotabsearchtextbox')))\n",
    "\n",
    "\n",
    "    max_retries = 5\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            search_box = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.ID, 'twotabsearchtextbox')))\n",
    "            break  # Exit the loop if the element is found\n",
    "        except TimeoutException:\n",
    "            if retry == max_retries - 1:\n",
    "                # Handle the timeout after maximum retries\n",
    "                print(\"Element not found after maximum retries.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Retry {retry + 1}: Element not found. Retrying...\")\n",
    "    search_box.send_keys(search_query)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "    # Find and extract all product links on the search results page\n",
    "    product_links = driver.find_elements(By.CSS_SELECTOR, '.s-result-item a.a-link-normal.s-no-outline')\n",
    "    product_urls = [link.get_attribute('href') for link in product_links]\n",
    "\n",
    "    # Initialize a list to store reviews\n",
    "    reviews_data = []\n",
    "\n",
    "    # Loop through product links and extract reviews\n",
    "    for product_url in product_urls:\n",
    "        driver.get(product_url)\n",
    "        time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "        try:\n",
    "            # Extract the product name\n",
    "            product_name = driver.find_element(By.ID, 'productTitle').text\n",
    "\n",
    "            # Check if the product name contains the filter string (case-insensitive)\n",
    "            if search_query.lower() in product_name.lower():\n",
    "                # Click on the \"See all reviews\" link (if available)\n",
    "                try:\n",
    "                    see_all_reviews_link = driver.find_element(By.PARTIAL_LINK_TEXT, 'See more reviews')\n",
    "                    see_all_reviews_link.click()\n",
    "                    time.sleep(2)  # Adjust the sleep time as needed to allow the reviews page to load\n",
    "\n",
    "                    # Extract and store all reviews on the page\n",
    "                    review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "\n",
    "                    # Initialize a list to store reviews as dictionaries\n",
    "                    # reviews_data = []\n",
    "\n",
    "                    # Loop through review elements and extract user name, rating, title, date, country, and review text\n",
    "                    for review_element in review_elements:\n",
    "                        # Extract user name\n",
    "                        user_name_element = review_element.find_element(By.CSS_SELECTOR, '.a-profile')\n",
    "                        user_name = user_name_element.text\n",
    "\n",
    "                        # Extract star rating as an integer (1 to 5 stars)\n",
    "                        star_rating_element = review_element.find_elements(By.CSS_SELECTOR, '.a-icon-star .a-icon-alt')\n",
    "                        star_rating = 0\n",
    "                        if star_rating_element:\n",
    "                            # Extract the star rating from the alt text of the star icons\n",
    "                            star_rating_text = star_rating_element[0].get_attribute('innerHTML')\n",
    "                            star_rating =star_rating_text.split(' ')[0]\n",
    "\n",
    "                        # Extract review title\n",
    "                        review_title_element = review_element.find_element(By.CSS_SELECTOR, '.review-title')\n",
    "                        review_title = review_title_element.text\n",
    "\n",
    "                        # Extract review date and country\n",
    "                        review_date_element = review_element.find_element(By.CSS_SELECTOR, '.review-date')\n",
    "                        review_date_text = review_date_element.text\n",
    "                        review_date_parts = review_date_text.split('on')\n",
    "                        if len(review_date_parts) == 2:\n",
    "                            review_date = review_date_parts[0].strip()\n",
    "                            country = review_date_parts[1].strip()\n",
    "                        else:\n",
    "                            review_date = review_date_text.strip()\n",
    "                            country = \"\"\n",
    "\n",
    "                        # Extract review text\n",
    "                        review_text_element = review_element.find_element(By.CSS_SELECTOR, '.review-text-content')\n",
    "                        review_text = review_text_element.text\n",
    "\n",
    "                        # Store the extracted data in a dictionary\n",
    "                        review_data = {\n",
    "                            'User Name': user_name,\n",
    "                            'Rating': star_rating,\n",
    "                            'Title': review_title,\n",
    "                            'Date': review_date,\n",
    "                            'Country': country,\n",
    "                            'Review Text': review_text\n",
    "                        }\n",
    "\n",
    "                        reviews_data.append(review_data)\n",
    "                                        \n",
    "                except Exception as e:\n",
    "                    print(f\"No 'See all reviews' link found for product: {product_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "\n",
    "    return reviews_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nokia=scrape_amazon_reviews_df('nokia xr21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nokia=pd.DataFrame(reviews_nokia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nokia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.amazon.com/Nokia-Unlocked-Smartphone-6-49-Inch-Midnight/product-reviews/B0C9NXM214/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'\n",
    "\n",
    "# Navigate to the Amazon product review page\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# Find and extract the review elements\n",
    "review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "\n",
    "# Initialize a list to store reviews as dictionaries\n",
    "reviews_data = []\n",
    "\n",
    "# Loop through review elements and extract user name, rating, title, date, country, and review text\n",
    "for review_element in review_elements:\n",
    "    # Extract user name\n",
    "    user_name_element = review_element.find_element(By.CSS_SELECTOR, '.a-profile')\n",
    "    user_name = user_name_element.text\n",
    "\n",
    "    # Extract star rating as an integer (1 to 5 stars)\n",
    "    star_rating_element = review_element.find_elements(By.CSS_SELECTOR, '.a-icon-star .a-icon-alt')\n",
    "    star_rating = 0\n",
    "    if star_rating_element:\n",
    "        # Extract the star rating from the alt text of the star icons\n",
    "        star_rating_text = star_rating_element[0].get_attribute('innerHTML')\n",
    "        star_rating =star_rating_text.split(' ')[0]\n",
    "\n",
    "    # Extract review title\n",
    "    review_title_element = review_element.find_element(By.CSS_SELECTOR, '.review-title')\n",
    "    review_title = review_title_element.text\n",
    "\n",
    "    # Extract review date and country\n",
    "    review_date_element = review_element.find_element(By.CSS_SELECTOR, '.review-date')\n",
    "    review_date_text = review_date_element.text\n",
    "    review_date_parts = review_date_text.split('on')\n",
    "    if len(review_date_parts) == 2:\n",
    "        review_date = review_date_parts[0].strip()\n",
    "        country = review_date_parts[1].strip()\n",
    "    else:\n",
    "        review_date = review_date_text.strip()\n",
    "        country = \"\"\n",
    "\n",
    "    # Extract review text\n",
    "    review_text_element = review_element.find_element(By.CSS_SELECTOR, '.review-text-content')\n",
    "    review_text = review_text_element.text\n",
    "\n",
    "    # Store the extracted data in a dictionary\n",
    "    review_data = {\n",
    "        'User Name': user_name,\n",
    "        'Rating': star_rating,\n",
    "        'Title': review_title,\n",
    "        'Date': review_date,\n",
    "        'Country': country,\n",
    "        'Review Text': review_text\n",
    "    }\n",
    "\n",
    "    reviews_data.append(review_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rating_element = driver.find_elements(By.CSS_SELECTOR, '.review-rating').text\n",
    "#star_rating = int(star_rating_element.get_attribute('title').split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rating_element.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "options=Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "driver.get('https://www.amazon.com/SAMSUNG-Unlocked-Smartphone-Foldable-Compatible/dp/B0B4FBKLWP/ref=sr_1_48?crid=3LVSQ058I3PYZ&keywords=xiaomi%2Bredmi%2Bnote%2B12&qid=1697016658&sprefix=%2Caps%2C256&sr=8-48&th=1')\n",
    "time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "reviews_data=[]\n",
    "\n",
    "    # Check if the product name contains the search query (case-insensitive)\n",
    "\n",
    "see_all_reviews_link = driver.find_element(By.PARTIAL_LINK_TEXT, 'See more reviews')\n",
    "see_all_reviews_link.click()\n",
    "time.sleep(2)\n",
    "sort_by_dropdown = driver.find_element(By.ID, 'sort-order-dropdown')\n",
    "\n",
    "# Create an ActionChains object to perform the click action\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(sort_by_dropdown).click().perform()\n",
    "\n",
    "# Select \"Most recent\" from the sorting options\n",
    "most_recent_option = driver.find_element(By.PARTIAL_LINK_TEXT, 'Most recent')\n",
    "\n",
    "# Create a new ActionChains object to click the \"Most recent\" option\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(most_recent_option).click().perform()\n",
    "time.sleep(2)\n",
    "while True:\n",
    "# Extract and store reviews on the current page\n",
    "    review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "\n",
    "    for review_element in review_elements:\n",
    "        # Extract user name, rating, title, date, country, and review text\n",
    "        user_name_element = review_element.find_element(By.CSS_SELECTOR, '.a-profile')\n",
    "        user_name = user_name_element.text\n",
    "\n",
    "        star_rating_element = review_element.find_elements(By.CSS_SELECTOR, '.a-icon-star .a-icon-alt')\n",
    "        star_rating = 0\n",
    "        if star_rating_element:\n",
    "            star_rating_text = star_rating_element[0].get_attribute('innerHTML')\n",
    "            star_rating = star_rating_text.split(' ')[0]\n",
    "\n",
    "        review_title_element = review_element.find_element(By.CSS_SELECTOR, '.review-title')\n",
    "        review_title = review_title_element.text\n",
    "\n",
    "        review_date_element = review_element.find_element(By.CSS_SELECTOR, '.review-date')\n",
    "        review_date_text = review_date_element.text\n",
    "        review_date_parts = review_date_text.split('on')\n",
    "        if len(review_date_parts) == 2:\n",
    "            review_date = review_date_parts[0].strip()\n",
    "            country = review_date_parts[1].strip()\n",
    "        else:\n",
    "            review_date = review_date_text.strip()\n",
    "            country = \"\"\n",
    "\n",
    "        review_text_element = review_element.find_element(By.CSS_SELECTOR, '.review-text-content')\n",
    "        review_text = review_text_element.text\n",
    "\n",
    "        review_data = {\n",
    "            'User Name': user_name,\n",
    "            'Rating': star_rating,\n",
    "            'Title': review_title,\n",
    "            'Date': review_date,\n",
    "            'Country': country,\n",
    "            'Review Text': review_text\n",
    "        }\n",
    "\n",
    "        reviews_data.append(review_data)\n",
    "\n",
    "    # Check if there's a \"Next\" button for the next page of reviews\n",
    "    next_button = driver.find_element(By.XPATH, '//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]')\n",
    "    if 'a-disabled' in next_button.get_attribute('class'):\n",
    "        # If the \"Next\" button is disabled, break the loop\n",
    "        break\n",
    "    else:\n",
    "        # Click the \"Next\" button to navigate to the next page of reviews\n",
    "        next_button.click()\n",
    "        time.sleep(2)  # Adjust the sleep time as needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Close the web driver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the scraped reviews data\n",
    "reviews_df = pd.DataFrame(reviews_data)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df=scrape_amazon_reviews_df('samsung galaxy S23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df.loc[samsung_df['Rating']=='1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "# options=Options()\n",
    "# options.add_argument('--headless')\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "url = 'https://www.gsmarena.com/oneplus_9-10747.php'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.get(url)\n",
    "product_id=url.split('-')[1].split('.')[0]\n",
    "list_df=pd.read_html(driver.page_source)\n",
    "return_df = pd.concat(list_df, ignore_index=True)\n",
    "return_df=return_df[:75]\n",
    "return_df[1] = return_df[0] + '_' + return_df[1]\n",
    "return_df=return_df.dropna(subset=1)\n",
    "return_df.reset_index()\n",
    "result=return_df.T\n",
    "result.columns=result.iloc[1]\n",
    "data_row=result.iloc[2]\n",
    "result_df=pd.DataFrame([data_row])\n",
    "try:\n",
    "    name = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"body\"]/div/div[1]/div/div[1]/h1'))).text\n",
    "except:\n",
    "    name=None\n",
    "result_df.insert(0,'brand',name.split(' ')[0])\n",
    "result_df.insert(1,'model',name.split(' ',1)[1])\n",
    "result_df.insert(0,'product_id',product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id=url.split('-')[1].split('.')[0]\n",
    "list_df=pd.read_html(driver.page_source)\n",
    "return_df = pd.concat(list_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=return_df.iloc[-3:].T\n",
    "result.columns=result.iloc[0]\n",
    "data_row=result.iloc[1]\n",
    "result_df=pd.DataFrame([data_row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.insert(0,'product_id',product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "options=Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls=['https://www.gsmarena.com/oneplus_9-10747.php','https://www.gsmarena.com/apple_iphone_13-11103.php','https://www.gsmarena.com/huawei_y9_(2019)-9324.php']\n",
    "prices_df=return_all_prices_df(driver,product_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_pl_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
