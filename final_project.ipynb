{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from misc_handler import extract_reviews_from_page,extract_all_reviews,scrape_amazon_reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "options=Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "url = 'https://www.phonearena.com/phones/Samsung-Galaxy-S23-FE_id12188'\n",
    "driver.get(url)\n",
    "#name=driver.find_elements(By.XPATH,'//*[@id=\"body\"]/div/div[1]/div/div[1]/h1')\n",
    "#name = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"body\"]/div/div[1]/div/div[1]/h1'))).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[0].columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[0][d22[0].columns[0]]=d22[0].columns[0]+'_'+d22[0][d22[0].columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= d22[0].T\n",
    "result.columns=result.iloc[0]\n",
    "data_row=result.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresult=pd.DataFrame([data_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=d22[0].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd=pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d1=pd.concat([d1,dd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(d22, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.json_normalize(response[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs=pd.json_normalize(response['snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(specs['ti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_html('https://phonedb.net/index.php?m=device&id=21724&c=samsung_sm-s918q_galaxy_s23_ultra_5g_uw_premium_edition_td-lte_jp_1tb__samsung_diamond_dm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_html('https://www.phonearena.com/phones/Samsung-Galaxy-S23-FE_id12188')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "res=d22[i].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd=pd.DataFrame([data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=dd.reset_index()\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "res=d22[i].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd2=pd.DataFrame([data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2=dd2.reset_index()\n",
    "dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([dd,dd2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)\n",
    "final = pd.DataFrame(columns=[0,1])\n",
    "for i in range(len(d22)):\n",
    "    d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "    d22[i].columns=[0,1]\n",
    "    #result = d22[i].T\n",
    "    #result.columns = result.iloc[0]\n",
    "    #data_row = result.iloc[1]\n",
    "    #fresult = pd.DataFrame([data_row])\n",
    "    #fresult=fresult.reset_index()\n",
    "    \n",
    "    if final is None:\n",
    "        final = fresult\n",
    "    else:\n",
    "        # Use ignore_index=True to concatenate without reindexing\n",
    "        final = pd.concat([final, d22[i]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22=pd.read_html(driver.page_source)\n",
    "final = pd.DataFrame(columns=[0,1])\n",
    "for i in range(len(d22)):\n",
    "    d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "    d22[i].columns=[0,1]\n",
    "    #result = d22[i].T\n",
    "    #result.columns = result.iloc[0]\n",
    "    #data_row = result.iloc[1]\n",
    "    #fresult = pd.DataFrame([data_row])\n",
    "    #fresult=fresult.reset_index()\n",
    "    \n",
    "    if final is None:\n",
    "        final = fresult\n",
    "    else:\n",
    "        # Use ignore_index=True to concatenate without reindexing\n",
    "        final = pd.concat([final, d22[i]],axis=0)\n",
    "\n",
    "result=final.T\n",
    "result.columns=result.iloc[0]\n",
    "col=result.iloc[0]\n",
    "arena_df=result.iloc[1:,:]\n",
    "arena_df.iloc[:,10:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_row.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=4\n",
    "d22[i][d22[i].columns[0]]=d22[i].columns[0]+'_'+d22[i][d22[i].columns[0]]\n",
    "res=d22[i].T\n",
    "res.columns=res.iloc[0]\n",
    "data=res.iloc[1]\n",
    "dd4=pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd4=dd4.reset_index()\n",
    "final = pd.concat([final, dd4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_handler import return_specs_df\n",
    "return_s23df=return_specs_df('https://www.gsmarena.com/google_pixel_8_pro-12545.php')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_s23df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "options=Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "#driver.get('https://www.gsmarena.com/samsung_galaxy_s23-reviews-12082.php')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=extract_all_reviews('https://www.gsmarena.com/alcatel_1b_(2022)-reviews-11706.php',driver=driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_elements = driver.find_elements(By.CLASS_NAME, 'user-thread')\n",
    "reviews = [review.text for review in review_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.gsmarena.com/samsung_galaxy_s23-reviews-12082p1.php')\n",
    "review_elements = driver.find_elements(By.CLASS_NAME, 'user-thread')\n",
    "\n",
    "# Loop through the review elements to extract user name, rating, and date\n",
    "reviews_data = []\n",
    "for review_element in review_elements:\n",
    "    user_name_element = review_element.find_element(By.XPATH, './/*[contains(@class, \"uname\") or contains(@class, \"uname2\")]')\n",
    "    user_location_element = review_element.find_element(By.CLASS_NAME, 'ulocation')\n",
    "    date_element = review_element.find_element(By.CLASS_NAME, 'upost')\n",
    "    text_element=review_element.find_element(By.CLASS_NAME, 'uopin')\n",
    "    \n",
    "    user_name = user_name_element.text\n",
    "    user_location = user_location_element.text\n",
    "    date = date_element.text\n",
    "    \n",
    "    review_text = text_element.text  # Extract the entire review text if needed\n",
    "    \n",
    "    reviews_data.append({\n",
    "        'User Name': user_name,\n",
    "        'User location': user_location,\n",
    "        'Date': date,\n",
    "        'Review Text': review_text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df=pd.DataFrame(reviews_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number=1\n",
    "driver.get(f'https://www.gsmarena.com/samsung_galaxy_s23-reviews-12082p{page_number}.php')\n",
    "review_elements = driver.find_elements(By.CLASS_NAME, 'user-thread')\n",
    "\n",
    "# Loop through the review elements to extract user name, rating, and date\n",
    "\n",
    "reviews_data = []\n",
    "for review_element in review_elements:\n",
    "    user_name_element = review_element.find_element(By.XPATH, './/*[contains(@class, \"uname\") or contains(@class, \"uname2\")]')\n",
    "    user_location_element = review_element.find_element(By.CLASS_NAME, 'ulocation')\n",
    "    date_element = review_element.find_element(By.CLASS_NAME, 'upost')\n",
    "    text_element=review_element.find_element(By.CLASS_NAME, 'uopin')\n",
    "    \n",
    "    user_name = user_name_element.text\n",
    "    user_location = user_location_element.text\n",
    "    date = date_element.text\n",
    "    \n",
    "    review_text = text_element.text  # Extract the entire review text if needed\n",
    "    \n",
    "    reviews_data.append({\n",
    "        'User Name': user_name,\n",
    "        'User location': user_location,\n",
    "        'Date': date,\n",
    "        'Review Text': review_text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scrape_amazon_reviews(search_query):\n",
    "    # Configure Selenium to use a web driver (e.g., ChromeDriver)\n",
    "    driver = webdriver.Chrome()\n",
    "    options=Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Navigate to Amazon's search results page\n",
    "    base_url = 'https://www.amazon.com/'\n",
    "    driver.get(base_url)\n",
    "    #search_box = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "    search_box = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.ID, 'twotabsearchtextbox')))\n",
    "    search_box.send_keys(search_query)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "    # Find and extract all product links on the search results page\n",
    "    product_links = driver.find_elements(By.CSS_SELECTOR, '.s-result-item a.a-link-normal.s-no-outline')\n",
    "    product_urls = [link.get_attribute('href') for link in product_links]\n",
    "\n",
    "    # Initialize a list to store reviews\n",
    "    all_reviews = []\n",
    "\n",
    "    # Loop through product links and extract reviews\n",
    "    for product_url in product_urls:\n",
    "        driver.get(product_url)\n",
    "        time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "        try:\n",
    "            # Extract the product name\n",
    "            product_name = driver.find_element(By.ID, 'productTitle').text\n",
    "\n",
    "            # Check if the product name contains the filter string (case-insensitive)\n",
    "            if search_query.lower() in product_name.lower():\n",
    "                # Click on the \"See all reviews\" link (if available)\n",
    "                try:\n",
    "                    see_all_reviews_link = driver.find_element(By.PARTIAL_LINK_TEXT, 'See more reviews')\n",
    "                    see_all_reviews_link.click()\n",
    "                    time.sleep(2)  # Adjust the sleep time as needed to allow the reviews page to load\n",
    "\n",
    "                    # Extract and store all reviews on the page\n",
    "                    review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "                    for review_element in review_elements:\n",
    "                        review_text = review_element.text\n",
    "                        all_reviews.append(review_text)\n",
    "                except Exception as e:\n",
    "                    print(f\"No 'See all reviews' link found for product: {product_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_amazon_reviews_df(search_query):\n",
    "    # Configure Selenium to use a web driver (e.g., ChromeDriver)\n",
    "    driver = webdriver.Chrome()\n",
    "    options=Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Navigate to Amazon's search results page\n",
    "    base_url = 'https://www.amazon.com/'\n",
    "    driver.get(base_url)\n",
    "    #search_box = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "    #earch_box = WebDriverWait(driver, 50).until(EC.element_to_be_clickable((By.ID, 'twotabsearchtextbox')))\n",
    "\n",
    "\n",
    "    max_retries = 5\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            search_box = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.ID, 'twotabsearchtextbox')))\n",
    "            break  # Exit the loop if the element is found\n",
    "        except TimeoutException:\n",
    "            if retry == max_retries - 1:\n",
    "                # Handle the timeout after maximum retries\n",
    "                print(\"Element not found after maximum retries.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Retry {retry + 1}: Element not found. Retrying...\")\n",
    "    search_box.send_keys(search_query)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "    # Find and extract all product links on the search results page\n",
    "    product_links = driver.find_elements(By.CSS_SELECTOR, '.s-result-item a.a-link-normal.s-no-outline')\n",
    "    product_urls = [link.get_attribute('href') for link in product_links]\n",
    "\n",
    "    # Initialize a list to store reviews\n",
    "    reviews_data = []\n",
    "\n",
    "    # Loop through product links and extract reviews\n",
    "    for product_url in product_urls:\n",
    "        driver.get(product_url)\n",
    "        time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "        try:\n",
    "            # Extract the product name\n",
    "            product_name = driver.find_element(By.ID, 'productTitle').text\n",
    "\n",
    "            # Check if the product name contains the filter string (case-insensitive)\n",
    "            if search_query.lower() in product_name.lower():\n",
    "                # Click on the \"See all reviews\" link (if available)\n",
    "                try:\n",
    "                    see_all_reviews_link = driver.find_element(By.PARTIAL_LINK_TEXT, 'See more reviews')\n",
    "                    see_all_reviews_link.click()\n",
    "                    time.sleep(2)  # Adjust the sleep time as needed to allow the reviews page to load\n",
    "\n",
    "                    # Extract and store all reviews on the page\n",
    "                    review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "\n",
    "                    # Initialize a list to store reviews as dictionaries\n",
    "                    # reviews_data = []\n",
    "\n",
    "                    # Loop through review elements and extract user name, rating, title, date, country, and review text\n",
    "                    for review_element in review_elements:\n",
    "                        # Extract user name\n",
    "                        user_name_element = review_element.find_element(By.CSS_SELECTOR, '.a-profile')\n",
    "                        user_name = user_name_element.text\n",
    "\n",
    "                        # Extract star rating as an integer (1 to 5 stars)\n",
    "                        star_rating_element = review_element.find_elements(By.CSS_SELECTOR, '.a-icon-star .a-icon-alt')\n",
    "                        star_rating = 0\n",
    "                        if star_rating_element:\n",
    "                            # Extract the star rating from the alt text of the star icons\n",
    "                            star_rating_text = star_rating_element[0].get_attribute('innerHTML')\n",
    "                            star_rating =star_rating_text.split(' ')[0]\n",
    "\n",
    "                        # Extract review title\n",
    "                        review_title_element = review_element.find_element(By.CSS_SELECTOR, '.review-title')\n",
    "                        review_title = review_title_element.text\n",
    "\n",
    "                        # Extract review date and country\n",
    "                        review_date_element = review_element.find_element(By.CSS_SELECTOR, '.review-date')\n",
    "                        review_date_text = review_date_element.text\n",
    "                        review_date_parts = review_date_text.split('on')\n",
    "                        if len(review_date_parts) == 2:\n",
    "                            review_date = review_date_parts[0].strip()\n",
    "                            country = review_date_parts[1].strip()\n",
    "                        else:\n",
    "                            review_date = review_date_text.strip()\n",
    "                            country = \"\"\n",
    "\n",
    "                        # Extract review text\n",
    "                        review_text_element = review_element.find_element(By.CSS_SELECTOR, '.review-text-content')\n",
    "                        review_text = review_text_element.text\n",
    "\n",
    "                        # Store the extracted data in a dictionary\n",
    "                        review_data = {\n",
    "                            'User Name': user_name,\n",
    "                            'Rating': star_rating,\n",
    "                            'Title': review_title,\n",
    "                            'Date': review_date,\n",
    "                            'Country': country,\n",
    "                            'Review Text': review_text\n",
    "                        }\n",
    "\n",
    "                        reviews_data.append(review_data)\n",
    "                                        \n",
    "                except Exception as e:\n",
    "                    print(f\"No 'See all reviews' link found for product: {product_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "\n",
    "    return reviews_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nokia=scrape_amazon_reviews_df('nokia xr21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nokia=pd.DataFrame(reviews_nokia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nokia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.amazon.com/Nokia-Unlocked-Smartphone-6-49-Inch-Midnight/product-reviews/B0C9NXM214/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'\n",
    "\n",
    "# Navigate to the Amazon product review page\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# Find and extract the review elements\n",
    "review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "\n",
    "# Initialize a list to store reviews as dictionaries\n",
    "reviews_data = []\n",
    "\n",
    "# Loop through review elements and extract user name, rating, title, date, country, and review text\n",
    "for review_element in review_elements:\n",
    "    # Extract user name\n",
    "    user_name_element = review_element.find_element(By.CSS_SELECTOR, '.a-profile')\n",
    "    user_name = user_name_element.text\n",
    "\n",
    "    # Extract star rating as an integer (1 to 5 stars)\n",
    "    star_rating_element = review_element.find_elements(By.CSS_SELECTOR, '.a-icon-star .a-icon-alt')\n",
    "    star_rating = 0\n",
    "    if star_rating_element:\n",
    "        # Extract the star rating from the alt text of the star icons\n",
    "        star_rating_text = star_rating_element[0].get_attribute('innerHTML')\n",
    "        star_rating =star_rating_text.split(' ')[0]\n",
    "\n",
    "    # Extract review title\n",
    "    review_title_element = review_element.find_element(By.CSS_SELECTOR, '.review-title')\n",
    "    review_title = review_title_element.text\n",
    "\n",
    "    # Extract review date and country\n",
    "    review_date_element = review_element.find_element(By.CSS_SELECTOR, '.review-date')\n",
    "    review_date_text = review_date_element.text\n",
    "    review_date_parts = review_date_text.split('on')\n",
    "    if len(review_date_parts) == 2:\n",
    "        review_date = review_date_parts[0].strip()\n",
    "        country = review_date_parts[1].strip()\n",
    "    else:\n",
    "        review_date = review_date_text.strip()\n",
    "        country = \"\"\n",
    "\n",
    "    # Extract review text\n",
    "    review_text_element = review_element.find_element(By.CSS_SELECTOR, '.review-text-content')\n",
    "    review_text = review_text_element.text\n",
    "\n",
    "    # Store the extracted data in a dictionary\n",
    "    review_data = {\n",
    "        'User Name': user_name,\n",
    "        'Rating': star_rating,\n",
    "        'Title': review_title,\n",
    "        'Date': review_date,\n",
    "        'Country': country,\n",
    "        'Review Text': review_text\n",
    "    }\n",
    "\n",
    "    reviews_data.append(review_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rating_element = driver.find_elements(By.CSS_SELECTOR, '.review-rating').text\n",
    "#star_rating = int(star_rating_element.get_attribute('title').split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rating_element.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "options=Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "driver.get('https://www.amazon.com/SAMSUNG-Unlocked-Smartphone-Foldable-Compatible/dp/B0B4FBKLWP/ref=sr_1_48?crid=3LVSQ058I3PYZ&keywords=xiaomi%2Bredmi%2Bnote%2B12&qid=1697016658&sprefix=%2Caps%2C256&sr=8-48&th=1')\n",
    "time.sleep(2)  # Adjust the sleep time as needed to allow the page to load\n",
    "\n",
    "reviews_data=[]\n",
    "\n",
    "    # Check if the product name contains the search query (case-insensitive)\n",
    "\n",
    "see_all_reviews_link = driver.find_element(By.PARTIAL_LINK_TEXT, 'See more reviews')\n",
    "see_all_reviews_link.click()\n",
    "time.sleep(2)\n",
    "sort_by_dropdown = driver.find_element(By.ID, 'sort-order-dropdown')\n",
    "\n",
    "# Create an ActionChains object to perform the click action\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(sort_by_dropdown).click().perform()\n",
    "\n",
    "# Select \"Most recent\" from the sorting options\n",
    "most_recent_option = driver.find_element(By.PARTIAL_LINK_TEXT, 'Most recent')\n",
    "\n",
    "# Create a new ActionChains object to click the \"Most recent\" option\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(most_recent_option).click().perform()\n",
    "time.sleep(2)\n",
    "while True:\n",
    "# Extract and store reviews on the current page\n",
    "    review_elements = driver.find_elements(By.CSS_SELECTOR, '.a-section.review .a-section.celwidget')\n",
    "\n",
    "    for review_element in review_elements:\n",
    "        # Extract user name, rating, title, date, country, and review text\n",
    "        user_name_element = review_element.find_element(By.CSS_SELECTOR, '.a-profile')\n",
    "        user_name = user_name_element.text\n",
    "\n",
    "        star_rating_element = review_element.find_elements(By.CSS_SELECTOR, '.a-icon-star .a-icon-alt')\n",
    "        star_rating = 0\n",
    "        if star_rating_element:\n",
    "            star_rating_text = star_rating_element[0].get_attribute('innerHTML')\n",
    "            star_rating = star_rating_text.split(' ')[0]\n",
    "\n",
    "        review_title_element = review_element.find_element(By.CSS_SELECTOR, '.review-title')\n",
    "        review_title = review_title_element.text\n",
    "\n",
    "        review_date_element = review_element.find_element(By.CSS_SELECTOR, '.review-date')\n",
    "        review_date_text = review_date_element.text\n",
    "        review_date_parts = review_date_text.split('on')\n",
    "        if len(review_date_parts) == 2:\n",
    "            review_date = review_date_parts[0].strip()\n",
    "            country = review_date_parts[1].strip()\n",
    "        else:\n",
    "            review_date = review_date_text.strip()\n",
    "            country = \"\"\n",
    "\n",
    "        review_text_element = review_element.find_element(By.CSS_SELECTOR, '.review-text-content')\n",
    "        review_text = review_text_element.text\n",
    "\n",
    "        review_data = {\n",
    "            'User Name': user_name,\n",
    "            'Rating': star_rating,\n",
    "            'Title': review_title,\n",
    "            'Date': review_date,\n",
    "            'Country': country,\n",
    "            'Review Text': review_text\n",
    "        }\n",
    "\n",
    "        reviews_data.append(review_data)\n",
    "\n",
    "    # Check if there's a \"Next\" button for the next page of reviews\n",
    "    next_button = driver.find_element(By.XPATH, '//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]')\n",
    "    if 'a-disabled' in next_button.get_attribute('class'):\n",
    "        # If the \"Next\" button is disabled, break the loop\n",
    "        break\n",
    "    else:\n",
    "        # Click the \"Next\" button to navigate to the next page of reviews\n",
    "        next_button.click()\n",
    "        time.sleep(2)  # Adjust the sleep time as needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Close the web driver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the scraped reviews data\n",
    "reviews_df = pd.DataFrame(reviews_data)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a\n",
    "\n",
    "//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a\n",
    "\n",
    "//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a/text()\n",
    "\n",
    "//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]\n",
    "//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]\n",
    "\n",
    "#sort-order-dropdown\n",
    "#sort-order-dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df=scrape_amazon_reviews_df('samsung galaxy S23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df.loc[samsung_df['Rating']=='1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reddit_comments(search_query, num_results=3):\n",
    "    # Configure Selenium to use a web driver\n",
    "    driver = webdriver.Chrome()\n",
    "    options=Options()\n",
    "    #options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get('https://www.reddit.com/r/Android/search/?q=Samsung+Galaxy+S23&type=link&cId=f8a8a872-e196-4dae-8d34-c5699011f6df&iId=d62fdb50-6312-42c6-a586-a19ccf79312b')\n",
    "\n",
    "    # Perform a Reddit site search\n",
    "    #WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'search-input')))\n",
    "\n",
    "# Find and interact with the search box\n",
    "    # search_box =WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"search-input\"]//label/div/span[2]/input')))\n",
    "    # search_box.send_keys(search_query)\n",
    "    # search_box.submit()\n",
    "\n",
    "    # Wait for search results to load\n",
    "\n",
    "\n",
    "    # Extract post links from search results\n",
    "    post_links = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/r/\"]')\n",
    "    processed_urls = set()\n",
    "    # Initialize lists to store data\n",
    "    usernames = []\n",
    "    dates = []\n",
    "    comments = []\n",
    "    #return post_links\n",
    "    for post_link in post_links:\n",
    "        post_url = post_link.get_attribute('href')\n",
    "        #return post_url\n",
    "        if '/comments/' in post_url:\n",
    "            if post_url not in processed_urls:\n",
    "                driver.get(post_url)\n",
    "\n",
    "            # Extract the post title\n",
    "                post_title = driver.find_element(By.CSS_SELECTOR, 'h1').text\n",
    "                if search_query.lower() in post_title.lower():\n",
    "\n",
    "                # Extract comments\n",
    "                    comments_elements = driver.find_elements(By.CSS_SELECTOR, '.comment')\n",
    "\n",
    "                    for comment_element in comments_elements:\n",
    "                        username = comment_element.find_element(By.CSS_SELECTOR, '.author').text\n",
    "                        date = comment_element.find_element(By.CSS_SELECTOR, '.live-timestamp').get_attribute('datetime')\n",
    "                        comment_text = comment_element.find_element(By.CSS_SELECTOR, '.md').text\n",
    "\n",
    "                        usernames.append(username)\n",
    "                        dates.append(date)\n",
    "                        comments.append(comment_text)\n",
    "                processed_urls.add(post_url)\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    data = {\n",
    "        'User Name': usernames,\n",
    "        'Date': [pd.to_datetime(date) for date in dates],\n",
    "        'Review Text': comments,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found\n  (Session info: chrome=117.0.5938.150); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF68D9C7D12+55474]\n\t(No symbol) [0x00007FF68D9377C2]\n\t(No symbol) [0x00007FF68D7EE0EB]\n\t(No symbol) [0x00007FF68D7FB8AA]\n\t(No symbol) [0x00007FF68D7F2F09]\n\t(No symbol) [0x00007FF68D7F3013]\n\t(No symbol) [0x00007FF68D7F1DC2]\n\t(No symbol) [0x00007FF68D7F495A]\n\t(No symbol) [0x00007FF68D868584]\n\t(No symbol) [0x00007FF68D84F15A]\n\t(No symbol) [0x00007FF68D867EF2]\n\t(No symbol) [0x00007FF68D84EF33]\n\t(No symbol) [0x00007FF68D823D41]\n\t(No symbol) [0x00007FF68D824F84]\n\tGetHandleVerifier [0x00007FF68DD2B762+3609346]\n\tGetHandleVerifier [0x00007FF68DD81A80+3962400]\n\tGetHandleVerifier [0x00007FF68DD79F0F+3930799]\n\tGetHandleVerifier [0x00007FF68DA63CA6+694342]\n\t(No symbol) [0x00007FF68D942218]\n\t(No symbol) [0x00007FF68D93E484]\n\t(No symbol) [0x00007FF68D93E5B2]\n\t(No symbol) [0x00007FF68D92EE13]\n\tBaseThreadInitThunk [0x00007FF8B5607344+20]\n\tRtlUserThreadStart [0x00007FF8B66626B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lenovo\\Desktop\\SE_Factory\\Final-FSD\\final_project.ipynb Cell 73\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m galaxy_df\u001b[39m=\u001b[39mscrape_reddit_comments(\u001b[39m'\u001b[39;49m\u001b[39mSamsung galaxy S23\u001b[39;49m\u001b[39m'\u001b[39;49m, num_results\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\lenovo\\Desktop\\SE_Factory\\Final-FSD\\final_project.ipynb Cell 73\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y132sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#return post_links\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y132sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m post_link \u001b[39min\u001b[39;00m post_links:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y132sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     post_url \u001b[39m=\u001b[39m post_link\u001b[39m.\u001b[39;49mget_attribute(\u001b[39m'\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y132sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m#return post_url\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y132sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m/comments/\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m post_url:\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\se_pl_analysis_env\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:177\u001b[0m, in \u001b[0;36mWebElement.get_attribute\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m getAttribute_js \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     _load_js()\n\u001b[1;32m--> 177\u001b[0m attribute_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mexecute_script(\n\u001b[0;32m    178\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/* getAttribute */return (\u001b[39;49m\u001b[39m{\u001b[39;49;00mgetAttribute_js\u001b[39m}\u001b[39;49;00m\u001b[39m).apply(null, arguments);\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m, name\n\u001b[0;32m    179\u001b[0m )\n\u001b[0;32m    180\u001b[0m \u001b[39mreturn\u001b[39;00m attribute_value\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\se_pl_analysis_env\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:404\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    401\u001b[0m converted_args \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(args)\n\u001b[0;32m    402\u001b[0m command \u001b[39m=\u001b[39m Command\u001b[39m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 404\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(command, {\u001b[39m\"\u001b[39;49m\u001b[39mscript\u001b[39;49m\u001b[39m\"\u001b[39;49m: script, \u001b[39m\"\u001b[39;49m\u001b[39margs\u001b[39;49m\u001b[39m\"\u001b[39;49m: converted_args})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\se_pl_analysis_env\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    345\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\se_pl_analysis_env\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: chrome=117.0.5938.150); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF68D9C7D12+55474]\n\t(No symbol) [0x00007FF68D9377C2]\n\t(No symbol) [0x00007FF68D7EE0EB]\n\t(No symbol) [0x00007FF68D7FB8AA]\n\t(No symbol) [0x00007FF68D7F2F09]\n\t(No symbol) [0x00007FF68D7F3013]\n\t(No symbol) [0x00007FF68D7F1DC2]\n\t(No symbol) [0x00007FF68D7F495A]\n\t(No symbol) [0x00007FF68D868584]\n\t(No symbol) [0x00007FF68D84F15A]\n\t(No symbol) [0x00007FF68D867EF2]\n\t(No symbol) [0x00007FF68D84EF33]\n\t(No symbol) [0x00007FF68D823D41]\n\t(No symbol) [0x00007FF68D824F84]\n\tGetHandleVerifier [0x00007FF68DD2B762+3609346]\n\tGetHandleVerifier [0x00007FF68DD81A80+3962400]\n\tGetHandleVerifier [0x00007FF68DD79F0F+3930799]\n\tGetHandleVerifier [0x00007FF68DA63CA6+694342]\n\t(No symbol) [0x00007FF68D942218]\n\t(No symbol) [0x00007FF68D93E484]\n\t(No symbol) [0x00007FF68D93E5B2]\n\t(No symbol) [0x00007FF68D92EE13]\n\tBaseThreadInitThunk [0x00007FF8B5607344+20]\n\tRtlUserThreadStart [0x00007FF8B66626B1+33]\n"
     ]
    }
   ],
   "source": [
    "galaxy_df=scrape_reddit_comments('Samsung galaxy S23', num_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [User Name, Date, Review Text]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/Android/comments/10x5ctx/samsung_galaxy_s23_review/\n",
      "https://www.reddit.com/r/Android/comments/10x5ctx/samsung_galaxy_s23_review/\n",
      "https://www.reddit.com/r/Android/comments/12rp3x0/s23_review_for_choosy_users/\n",
      "https://www.reddit.com/r/Android/comments/10zyb3b/samsung_galaxy_s23_ultra_review_gsmarenacom/\n",
      "https://www.reddit.com/r/Android/comments/10zyb3b/samsung_galaxy_s23_ultra_review_gsmarenacom/\n",
      "https://www.reddit.com/r/Android/comments/114aigc/samsung_galaxy_s23_ultra_review_stellar_battery/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for post_link in galaxy_df[1:14]:\n",
    "    post_url = post_link.get_attribute('href')\n",
    "    if '/comments/' in post_url:\n",
    "        print (post_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reddit_comments2(url):\n",
    "    # Configure Selenium to use a web driver (e.g., ChromeDriver)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    #post_links = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/r/\"]')\n",
    "    #return post_links\n",
    "    \n",
    "    # Click on the first link to access the article\n",
    "    post_links = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/r/\"]')\n",
    "    #return post_links\n",
    "    post_url = post_links[2].get_attribute('href')\n",
    "    driver.get(post_url)\n",
    "\n",
    "    # Wait for the discussion page to load\n",
    "    # WebDriverWait(driver, 10).until(\n",
    "    #     EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-test-id=\"comment\"]'))\n",
    "    # )\n",
    "\n",
    "    # Find the discussion elements\n",
    "    comment_elements = driver.find_elements(By.CSS_SELECTOR, '.pt-md.px-md.xs\\:px-0')\n",
    "    i=1\n",
    "    #return comment_elements[0].text\n",
    "    usernames = []\n",
    "    dates = []\n",
    "    comments = []\n",
    "    datas=[]\n",
    "    # Extract comments\n",
    "    try:\n",
    "        for comment_element in comment_elements:\n",
    "            username_element = comment_element.find_element(By.CSS_SELECTOR, 'faceplate-tracker[noun]')\n",
    "            username = username_element.get_attribute('noun')\n",
    "            date_element = comment_element.find_element(By.CSS_SELECTOR, 'time[datetime]')\n",
    "            date = date_element.get_attribute('datetime')\n",
    "            comment_text_element = comment_element.find_element(By.XPATH, f'/html/body/shreddit-app/div/main/faceplate-batch/faceplate-tracker/shreddit-comment-tree/shreddit-comment[{i}]/div[2]/div')\n",
    "            comment_text = comment_text_element.text\n",
    "            i+=1\n",
    "    \n",
    "            usernames.append(username)\n",
    "            dates.append(date)\n",
    "            comments.append(comment_text)\n",
    "\n",
    "        # Create a Pandas DataFrame\n",
    "            data = {\n",
    "                'User Name': username,\n",
    "                'Date': date,\n",
    "                'Review Text': comment_text,\n",
    "            }\n",
    "            datas.append(data)\n",
    "    except:\n",
    "        print(\"error\")\n",
    "    df = pd.DataFrame(datas)\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error: {e}\")\n",
    "    #     df = None\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "galaxy_df=scrape_reddit_comments2('https://www.reddit.com/r/Android/search/?q=Samsung+Galaxy+S23&type=link&cId=f6bfad84-3ac3-400f-99b2-983bba89051a&iId=910b273f-502e-4b1c-aecd-86c6052eb36c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>community</td>\n",
       "      <td>2023-02-08T17:31:07.008Z</td>\n",
       "      <td>The battery life upgrade is insane! Also a qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment_author_avatar</td>\n",
       "      <td>2023-02-08T22:39:46.789Z</td>\n",
       "      <td>Battery test score on the smallest S23 is just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment_author_avatar</td>\n",
       "      <td>2023-02-08T17:54:33.072Z</td>\n",
       "      <td>Pros\\nNo-nonsense sturdy and grippy design, IP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment_author_avatar</td>\n",
       "      <td>2023-02-08T17:32:50.490Z</td>\n",
       "      <td>Wow. This compact phone last longer than my 7 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment_author_avatar</td>\n",
       "      <td>2023-02-08T17:54:39.931Z</td>\n",
       "      <td>Better battery life than the iPhone 14 and 14 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comment_author_avatar</td>\n",
       "      <td>2023-02-08T20:44:20.444Z</td>\n",
       "      <td>I had to buy it. Perfect size flagship.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               User Name                      Date  \\\n",
       "0              community  2023-02-08T17:31:07.008Z   \n",
       "1  comment_author_avatar  2023-02-08T22:39:46.789Z   \n",
       "2  comment_author_avatar  2023-02-08T17:54:33.072Z   \n",
       "3  comment_author_avatar  2023-02-08T17:32:50.490Z   \n",
       "4  comment_author_avatar  2023-02-08T17:54:39.931Z   \n",
       "5  comment_author_avatar  2023-02-08T20:44:20.444Z   \n",
       "\n",
       "                                         Review Text  \n",
       "0  The battery life upgrade is insane! Also a qui...  \n",
       "1  Battery test score on the smallest S23 is just...  \n",
       "2  Pros\\nNo-nonsense sturdy and grippy design, IP...  \n",
       "3  Wow. This compact phone last longer than my 7 ...  \n",
       "4  Better battery life than the iPhone 14 and 14 ...  \n",
       "5            I had to buy it. Perfect size flagship.  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.reddit.com/r/Android/comments/10x5ctx/samsung_galaxy_s23_review/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community\n",
      "2023-02-08T17:31:07.008Z\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF68D9C7D12+55474]\n\t(No symbol) [0x00007FF68D9377C2]\n\t(No symbol) [0x00007FF68D7EE0EB]\n\t(No symbol) [0x00007FF68D82EBAC]\n\t(No symbol) [0x00007FF68D82ED2C]\n\t(No symbol) [0x00007FF68D869F77]\n\t(No symbol) [0x00007FF68D84F19F]\n\t(No symbol) [0x00007FF68D867EF2]\n\t(No symbol) [0x00007FF68D84EF33]\n\t(No symbol) [0x00007FF68D823D41]\n\t(No symbol) [0x00007FF68D824F84]\n\tGetHandleVerifier [0x00007FF68DD2B762+3609346]\n\tGetHandleVerifier [0x00007FF68DD81A80+3962400]\n\tGetHandleVerifier [0x00007FF68DD79F0F+3930799]\n\tGetHandleVerifier [0x00007FF68DA63CA6+694342]\n\t(No symbol) [0x00007FF68D942218]\n\t(No symbol) [0x00007FF68D93E484]\n\t(No symbol) [0x00007FF68D93E5B2]\n\t(No symbol) [0x00007FF68D92EE13]\n\tBaseThreadInitThunk [0x00007FF8B5607344+20]\n\tRtlUserThreadStart [0x00007FF8B66626B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lenovo\\Desktop\\SE_Factory\\Final-FSD\\final_project.ipynb Cell 80\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y142sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m date \u001b[39m=\u001b[39m date_element\u001b[39m.\u001b[39mget_attribute(\u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y142sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(date)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y142sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m comment_text_element \u001b[39m=\u001b[39m WebDriverWait(driver, \u001b[39m10\u001b[39;49m)\u001b[39m.\u001b[39;49muntil(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y142sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m      EC\u001b[39m.\u001b[39;49mpresence_of_element_located((By\u001b[39m.\u001b[39;49mXPATH, \u001b[39mf\u001b[39;49m\u001b[39m'''\u001b[39;49m\u001b[39m/html/body/shreddit-app/div/main/faceplate-batch/faceplate-tracker/shreddit-comment-tree/shreddit-comment[10]/div[2]/div\u001b[39;49m\u001b[39m'''\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y142sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m  )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y142sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m comment_text \u001b[39m=\u001b[39m comment_text_element\u001b[39m.\u001b[39mtext\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/SE_Factory/Final-FSD/final_project.ipynb#Y142sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(comment_text)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\se_pl_analysis_env\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m>\u001b[39m end_time:\n\u001b[0;32m     94\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF68D9C7D12+55474]\n\t(No symbol) [0x00007FF68D9377C2]\n\t(No symbol) [0x00007FF68D7EE0EB]\n\t(No symbol) [0x00007FF68D82EBAC]\n\t(No symbol) [0x00007FF68D82ED2C]\n\t(No symbol) [0x00007FF68D869F77]\n\t(No symbol) [0x00007FF68D84F19F]\n\t(No symbol) [0x00007FF68D867EF2]\n\t(No symbol) [0x00007FF68D84EF33]\n\t(No symbol) [0x00007FF68D823D41]\n\t(No symbol) [0x00007FF68D824F84]\n\tGetHandleVerifier [0x00007FF68DD2B762+3609346]\n\tGetHandleVerifier [0x00007FF68DD81A80+3962400]\n\tGetHandleVerifier [0x00007FF68DD79F0F+3930799]\n\tGetHandleVerifier [0x00007FF68DA63CA6+694342]\n\t(No symbol) [0x00007FF68D942218]\n\t(No symbol) [0x00007FF68D93E484]\n\t(No symbol) [0x00007FF68D93E5B2]\n\t(No symbol) [0x00007FF68D92EE13]\n\tBaseThreadInitThunk [0x00007FF8B5607344+20]\n\tRtlUserThreadStart [0x00007FF8B66626B1+33]\n"
     ]
    }
   ],
   "source": [
    "comment_elements = driver.find_elements(By.CSS_SELECTOR, '.pt-md.px-md.xs\\:px-0')\n",
    "i=1\n",
    "for comment_element in comment_elements:\n",
    "   \n",
    "   username_element = comment_element.find_element(By.CSS_SELECTOR, 'faceplate-tracker[noun]')\n",
    "   username = username_element.get_attribute('noun')\n",
    "   print(username)\n",
    "   date_element = comment_element.find_element(By.CSS_SELECTOR, 'time[datetime]')\n",
    "   date = date_element.get_attribute('datetime')\n",
    "   print(date)\n",
    "   comment_text_element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, f'''/html/body/shreddit-app/div/main/faceplate-batch/faceplate-tracker/shreddit-comment-tree/shreddit-comment[10]/div[2]/div'''))\n",
    "    )\n",
    "   comment_text = comment_text_element.text\n",
    "   print(comment_text)\n",
    "   i+=1\n",
    " \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_pl_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
